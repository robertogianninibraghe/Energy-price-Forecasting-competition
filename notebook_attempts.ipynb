{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTEBOOK WHERE WE EXPERIMENTED MANY MODELS\n",
    "for brevity we didn't create new experiment for every possible combination of model architecture and type of prediction(point with cp, distributionals, quantile regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_winkler_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the Winkler score on the test results\n",
    "    return: Winkler scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break\n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        delta_n = Upper - Lower\n",
    "        idx_up = np.greater(y_true, Upper)\n",
    "        idx_down = np.greater(Lower, y_true)\n",
    "        winkler = (idx_down * (delta_n + 2 / (1 - q * 2) * (Lower - y_true)) + idx_up * (\n",
    "                delta_n + 2 / (1 - q * 2) * (y_true - Upper)) + (~(idx_up | idx_down)) * delta_n)\n",
    "\n",
    "        loss_q = np.mean(winkler, axis=0)\n",
    "        score.append(loss_q)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "#exper_setup = 'QR-LSTM'\n",
    "exper_setup = 'N-DNN'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Load experiments configuration from json file\n",
    "configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "# Load dataset\n",
    "dir_path = os.getcwd()\n",
    "ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Instantiate recalibratione engine\n",
    "PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                               data_configs=configs['data_config'],\n",
    "                               model_configs=configs['model_config'])\n",
    "\n",
    "# Get model hyperparameters (previously saved or by tuning)\n",
    "model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "# Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "test_predictions = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                               plot_history=plot_train_history,\n",
    "                                               plot_weights=plot_weights)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Compute pinball score\n",
    "quantiles_levels = PrTSF_eng.model_configs['target_quantiles']\n",
    "pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "pinball_scores = compute_pinball_scores(y_true=test_predictions[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions.loc[:,test_predictions.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Plot test predictions\n",
    "plot_quantiles(test_predictions, target=PF_task_name)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    #print(quantiles_levels)\n",
    "    score = []\n",
    "    EC = []\n",
    "    #print((np.size(quantiles_levels)-1)/2)\n",
    "    #print((np.size(quantiles_levels)-1))\n",
    "    #print(pred_quantiles)\n",
    "\n",
    "    #quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels)-1)/2):]\n",
    "    \n",
    "    #print(useful_quantiles)\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break       \n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "\n",
    "        idx_up = np.greater_equal( Upper, y_true)\n",
    "        idx_down = np.greater_equal( y_true, Lower)\n",
    "        \n",
    "       \n",
    "        EC_alpha = np.mean(idx_up & idx_down)#quale asse\n",
    "\n",
    "        #print(np.mean(idx_up), np.mean(idx_down) ,EC_alpha, np.size(EC_alpha))\n",
    "\n",
    "        #score.append(delta_cov)\n",
    "        EC.append(np.abs(EC_alpha-(1-q*2)))#check\n",
    "        #print(1-q*2)\n",
    "\n",
    "    \n",
    "    score = 1/(2*(useful_quantiles[-1]-useful_quantiles[0]))*np.sum(EC)\n",
    "    #print(np.sum(EC))\n",
    "    #print(2*(useful_quantiles[-1]-useful_quantiles[0]))\n",
    "    print(EC)\n",
    "    return score\n",
    "\n",
    "\n",
    "delta_cov = compute_delta_cov(y_true=test_predictions[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions.loc[:,test_predictions.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "print(delta_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Generate the hours from 00:00 to 23:00\n",
    "average_pinball=np.mean(pinball_scores, axis=1)\n",
    "hours = np.arange(24)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(hours, pinball_scores)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('PInball Score')\n",
    "plt.title('Pinball Score vs Hour of the Day')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_winkler_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the Winkler score on the test results\n",
    "    return: Winkler scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break\n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        delta_n = Upper - Lower\n",
    "        idx_up = np.greater(y_true, Upper)\n",
    "        idx_down = np.greater(Lower, y_true)\n",
    "        winkler = (idx_down * (delta_n + 2 / (1 - q * 2) * (Lower - y_true)) + idx_up * (\n",
    "                delta_n + 2 / (1 - q * 2) * (y_true - Upper)) + (~(idx_up | idx_down)) * delta_n)\n",
    "\n",
    "        loss_q = np.mean(winkler, axis=0)\n",
    "        score.append(loss_q)\n",
    "    return score\n",
    "\n",
    "\n",
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    print(quantiles_levels)\n",
    "    score = []\n",
    "    EC = []\n",
    "    print((np.size(quantiles_levels)-1)/2)\n",
    "    print((np.size(quantiles_levels)-1))\n",
    "\n",
    "    #quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels)-1)/2):]\n",
    "    \n",
    "    print(useful_quantiles)\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break       \n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        idx_up = np.greater_equal( Upper, y_true)\n",
    "        idx_down = np.greater_equal( y_true, Lower)\n",
    "        print(idx_up, idx_down)\n",
    "        EC_alpha = np.mean(idx_up & idx_down)#quale asse\n",
    "        print(EC_alpha, np.size(EC_alpha))\n",
    "\n",
    "        #score.append(delta_cov)\n",
    "        EC.append(np.abs(EC_alpha-1+q*2))#check\n",
    "\n",
    "    \n",
    "    score = 1/(2*(useful_quantiles[-1]-useful_quantiles[0]))*np.sum(EC)\n",
    "    print(2*(useful_quantiles[-1]-useful_quantiles[0]))\n",
    "    print(np.sum(EC))\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "#exper_setup = 'N-DNN'\n",
    "#exper_setup = 'N-TRANSF'\n",
    "exper_setup = 'QR-DNN'\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Load experiments configuration from json file\n",
    "configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "# Load dataset\n",
    "dir_path = os.getcwd()\n",
    "ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Instantiate recalibratione engine\n",
    "PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                               data_configs=configs['data_config'],\n",
    "                               model_configs=configs['model_config'])\n",
    "\n",
    "# Get model hyperparameters (previously saved or by tuning)\n",
    "model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "# Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "test_predictions2 = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                               plot_history=plot_train_history,\n",
    "                                               plot_weights=plot_weights)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Compute pinball score\n",
    "quantiles_levels = PrTSF_eng.model_configs['target_quantiles']\n",
    "pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "pinball_scores2 = compute_pinball_scores(y_true=test_predictions2[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions2.loc[:,test_predictions2.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "\n",
    "\n",
    "delta_cov2 = compute_delta_cov(y_true=test_predictions2[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions2.loc[:,test_predictions2.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "print(delta_cov2)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Plot test predictions\n",
    "plot_quantiles(test_predictions2, target=PF_task_name)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "\n",
    "    score = []\n",
    "    EC = []\n",
    "\n",
    "    #print(pred_quantiles)\n",
    "\n",
    "    #quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels))/2):]\n",
    "    \n",
    "    print(useful_quantiles)\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break       \n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        idx_up = np.greater_equal( Upper, y_true)\n",
    "        idx_down = np.greater_equal( y_true, Lower)\n",
    "\n",
    "        EC_alpha = np.mean(idx_up & idx_down)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "        EC.append(np.abs(EC_alpha-(1-q*2)))#check\n",
    "        print(1-q*2)\n",
    "\n",
    "    \n",
    "    score = 1/(2*(useful_quantiles[-1]-useful_quantiles[0]))*np.sum(EC)\n",
    "   \n",
    "    return score\n",
    "\n",
    "\n",
    "delta_cov2 = compute_delta_cov(y_true=test_predictions2[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions2.loc[:,test_predictions2.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "print(delta_cov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the hours from 00:00 to 23:00\n",
    "average_pinball=np.mean(pinball_scores2, axis=1)\n",
    "hours = np.arange(24)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(hours, pinball_scores2)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('PInball Score')\n",
    "plt.title('Pinball Score vs Hour of the Day')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "from tools.conformal_prediction import compute_cp\n",
    "from tools.conformal_prediction import compute_weighted_cp\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "exper_setup = 'point-RNN'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Load experiments configuration from json file\n",
    "configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "# Load dataset\n",
    "dir_path = os.getcwd()\n",
    "ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Instantiate recalibratione engine\n",
    "PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                               data_configs=configs['data_config'],\n",
    "                               model_configs=configs['model_config'])\n",
    "\n",
    "# Get model hyperparameters (previously saved or by tuning)\n",
    "model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "# Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "test_predictions3 = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                               plot_history=plot_train_history,\n",
    "                                               plot_weights=plot_weights)\n",
    "print(test_predictions3.shape)\n",
    "print(test_predictions3.head())\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Conformal prediction settings\n",
    "exec_CP = True \n",
    "# set the size of the calibration set sufficiently large to cover the target alpha (tails)\n",
    "cp_settings={'target_alpha':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]}\n",
    "num_cali_samples = 184\n",
    "#num_cali_samples = 365\n",
    "#cp_settings={'target_alpha':[0.10]}\n",
    "#num_cali_samples = 31\n",
    "\n",
    "if exec_CP:\n",
    "    if exper_setup[:5]=='point':\n",
    "        # build the settings to build PF from point using CP\n",
    "        cp_settings['pred_horiz']=configs['data_config'].pred_horiz\n",
    "        cp_settings['task_name']=configs['data_config'].task_name\n",
    "        cp_settings['num_cali_samples']=num_cali_samples\n",
    "        # exec conformal prediction\n",
    "        \n",
    "        test_predictions4 = compute_cp(test_predictions3,cp_settings)\n",
    "        test_predictions5 = compute_weighted_cp(test_predictions3,cp_settings)\n",
    "    else:\n",
    "        print('conformal prediction implemented on point predictions')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Plot test predictions\n",
    "plot_quantiles(test_predictions4, target=PF_task_name)\n",
    "plot_quantiles(test_predictions5, target=PF_task_name)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Compute pinball score\n",
    "#quantiles_levels = PrTSF_eng.model_configs['target_quantiles'] #vecchio \n",
    "quantiles_levels = PrTSF_eng.__build_target_quantiles__(cp_settings['target_alpha'])\n",
    "pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "pinball_scores1 = compute_pinball_scores(y_true=test_predictions4[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions4.loc[:,test_predictions4.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "\n",
    "\n",
    "pinball_scores2 = compute_pinball_scores(y_true=test_predictions5[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions5.loc[:,test_predictions5.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "\n",
    "print(pinball_scores1, pinball_scores2)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPLEMENTED FUNCTIONS\n",
    "from cProfile import label\n",
    "from pickle import TRUE\n",
    "from matplotlib.pyplot import plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Flag è stringa per dire che metrica usare\n",
    "#average è un boleano, dice se calcolare hourly o mean, di default calcola hourly\n",
    "def compute_metrics(predicted, true, flag, average=False):\n",
    "    if average:    \n",
    "        if flag == 'RMSE':\n",
    "            error=  np.sqrt(np.mean(np.square(true - predicted)))    \n",
    "        elif flag == 'MAE':\n",
    "            error=np.mean((np.abs(true-predicted)))\n",
    "        elif flag == 'sMAPE':\n",
    "            error= 100*2*np.mean(np.abs(np.abs(true-predicted))/(np.abs(true)+np.abs(predicted)))\n",
    "        else:\n",
    "            print(\"Not a valid metric\")\n",
    "            return 0\n",
    "    else:\n",
    "        error=np.zeros(24)   \n",
    "        idx2=predicted.index            \n",
    "        if flag == 'RMSE':\n",
    "            for i in np.arange(24):\n",
    "                indices= idx2.hour==idx2[i].hour\n",
    "                error[i]=  np.sqrt(np.mean(np.square(true[indices] - predicted[indices])))    \n",
    "        elif flag == 'MAE':\n",
    "            for i in np.arange(24):\n",
    "                indices= idx2.hour==idx2[i].hour\n",
    "                error[i]= np.mean((np.abs(true[indices]-predicted[indices])))\n",
    "        elif flag == 'sMAPE':\n",
    "            for i in np.arange(24):\n",
    "                indices= idx2.hour==idx2[i].hour\n",
    "                error[i]= 100*2*np.mean(np.abs(true[indices]-predicted[indices])/(np.abs(true[indices])+np.abs(predicted[indices])))\n",
    "        else:\n",
    "            print(\"Not a valid metric\")\n",
    "            return error \n",
    "    return error\n",
    "  \n",
    "\n",
    "def full_evaluation(predicted, true):\n",
    "    metrics={\"RMSE\", \"MAE\", \"sMAPE\" }\n",
    "    hours = [f\"{hour:02}:00\" for hour in range(24)]\n",
    "    # Add an extra 'Average' row\n",
    "    hours.append('Average')\n",
    "    # Initialize the DataFrame with zeros\n",
    "    full_evaluation=pd.DataFrame(0, index=hours, columns=['RMSE', 'MAE', 'sMAPE'])\n",
    "    for st in metrics:\n",
    "        full_evaluation.loc[hours[:-1],st]=compute_metrics(true, predicted, st)\n",
    "        full_evaluation.loc[hours[-1],st]=compute_metrics(true, predicted, st, TRUE)\n",
    "        print(full_evaluation.loc[hours[-1],st], st)\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    idx=hours[:-1]\n",
    "    ones_vec=np.ones(24)\n",
    "    for st in metrics:\n",
    "        ax1.plot(idx,full_evaluation.loc[idx,st], linestyle=\"-\", linewidth=0.9, label=st)\n",
    "        ax1.plot(idx, ones_vec*full_evaluation.loc['Average',st], linestyle=\"-\", linewidth=0.9, label=st+\"_average\")\n",
    "    tics=hours[0:24:3]\n",
    "    ax1.set_xticks(tics)\n",
    "    #fig1.xticks(ticks=tics)\n",
    "    #fig1.gca().xaxis.set_ticks([tick for tick in ax1.gca().xaxis.get_ticks() if tick in tics])\n",
    "\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Error Metrics\")\n",
    "    fig1.show()\n",
    "    return full_evaluation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    " \n",
    "    score = []\n",
    "    EC = []\n",
    "\n",
    "    #quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels)-1)/2):]\n",
    "    \n",
    "\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break       \n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        \n",
    "       \n",
    "        idx_up = np.greater_equal( Upper, y_true)\n",
    "        idx_down = np.greater_equal( y_true, Lower)\n",
    "       \n",
    "        EC_alpha = np.mean(idx_up & idx_down)#quale asse\n",
    "        EC.append(np.abs(EC_alpha-(1-q*2)))\n",
    "        \n",
    "    \n",
    "    score = 1/(2*(useful_quantiles[-1]-useful_quantiles[0]))*np.sum(EC)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "delta_cov1 = compute_delta_cov(y_true=test_predictions4[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions4.loc[:,test_predictions4.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "print(delta_cov1)\n",
    "delta_cov2 = compute_delta_cov(y_true=test_predictions5[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions5.loc[:,test_predictions5.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "print(delta_cov1,delta_cov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metrics=full_evaluation(test_predictions4[0.5], test_predictions4[PF_task_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_predictions4[0.5], \"pred\")\n",
    "print(test_predictions4[PF_task_name].to_numpy().reshape(-1,pred_steps))\n",
    "print(test_predictions4[PF_task_name], \"true\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEC model( decomposition layer for seasonal and trend components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "from tools.conformal_prediction import compute_cp\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "exper_setup = 'point-DEC'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Load experiments configuration from json file\n",
    "configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "# Load dataset\n",
    "dir_path = os.getcwd()\n",
    "ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Instantiate recalibratione engine\n",
    "PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                               data_configs=configs['data_config'],\n",
    "                               model_configs=configs['model_config'])\n",
    "\n",
    "# Get model hyperparameters (previously saved or by tuning)\n",
    "model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "# Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "test_predictions3 = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                               plot_history=plot_train_history,\n",
    "                                               plot_weights=plot_weights)\n",
    "print(test_predictions3.shape)\n",
    "print(test_predictions3.head())\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Conformal prediction settings\n",
    "exec_CP = True \n",
    "# set the size of the calibration set sufficiently large to cover the target alpha (tails)\n",
    "cp_settings={'target_alpha':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]}\n",
    "num_cali_samples = 122\n",
    "#cp_settings={'target_alpha':[0.10]}\n",
    "#num_cali_samples = 31\n",
    "\n",
    "if exec_CP:\n",
    "    if exper_setup[:5]=='point':\n",
    "        # build the settings to build PF from point using CP\n",
    "        cp_settings['pred_horiz']=configs['data_config'].pred_horiz\n",
    "        cp_settings['task_name']=configs['data_config'].task_name\n",
    "        cp_settings['num_cali_samples']=num_cali_samples\n",
    "        # exec conformal prediction\n",
    "        print(cp_settings)\n",
    "        test_predictions3 = compute_cp(test_predictions3,cp_settings)\n",
    "    else:\n",
    "        print('conformal prediction implemented on point predictions')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Plot test predictions\n",
    "plot_quantiles(test_predictions3, target=PF_task_name)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Compute pinball score\n",
    "#quantiles_levels = PrTSF_eng.model_configs['target_quantiles'] #vecchio \n",
    "quantiles_levels = PrTSF_eng.__build_target_quantiles__(cp_settings['target_alpha'])\n",
    "pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "pinball_scores = compute_pinball_scores(y_true=test_predictions3[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions3.loc[:,test_predictions3.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the hours from 00:00 to 23:00\n",
    "average_pinball=np.mean(pinball_scores, axis=1)\n",
    "hours = np.arange(24)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(hours, pinball_scores)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('PInball Score')\n",
    "plt.title('Pinball Score vs Hour of the Day')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESIDUAL ENSEMBLED WITH ARX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "from tools.conformal_prediction import compute_cp\n",
    "from tools.conformal_prediction import compute_weighted_cp\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "\n",
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "\n",
    "    EC = []\n",
    "\n",
    "    # quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels) - 1) / 2):]\n",
    "    useful_quantiles.reverse()\n",
    "\n",
    "    for i, q in enumerate(useful_quantiles):\n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        print(q)\n",
    "\n",
    "        idx_up = np.greater_equal(Upper, y_true)\n",
    "        idx_down = np.greater_equal(y_true, Lower)\n",
    "        EC_alpha = np.mean(idx_up & idx_down)  # quale asse\n",
    "\n",
    "        # score.append(delta_cov)\n",
    "        EC.append(np.abs(EC_alpha - (1-(1-q)*2) ))  # check\n",
    "    score = 1 / (2 * (useful_quantiles[0] - useful_quantiles[-1])) * np.sum(EC)\n",
    "    return score\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = np.square(y_true - y_pred).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = np.square(y_true - y_pred).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "exper_setup = 'point-RES-ARX'\n",
    "results_d_cov = []\n",
    "results_weighted_d_cov = []\n",
    "results_rmse = []\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "\n",
    "num_run = 4\n",
    "for i in range(num_run):\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    # Load experiments configuration from json file\n",
    "    configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "    # Load dataset\n",
    "    dir_path = os.getcwd()\n",
    "    ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "    ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    # Instantiate recalibratione engine\n",
    "    PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                                   data_configs=configs['data_config'],\n",
    "                                   model_configs=configs['model_config'])\n",
    "\n",
    "\n",
    "    # Get model hyperparameters (previously saved or by tuning)\n",
    "    model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "    # Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "    test_predictions = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                                   plot_history=plot_train_history,\n",
    "                                                   plot_weights=plot_weights)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    # Conformal prediction settings\n",
    "    exec_CP = True\n",
    "    # set the size of the calibration set sufficiently large to cover the target alpha (tails)\n",
    "    cp_settings={'target_alpha':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]}\n",
    "    num_cali_samples = 365\n",
    "    #cp_settings={'target_alpha':[0.10]}\n",
    "    #num_cali_samples = 1\n",
    "\n",
    "    if exec_CP:\n",
    "        if exper_setup[:5]=='point':\n",
    "            # build the settings to build PF from point using CP\n",
    "            cp_settings['pred_horiz']=configs['data_config'].pred_horiz\n",
    "            cp_settings['task_name']=configs['data_config'].task_name\n",
    "            cp_settings['num_cali_samples']=num_cali_samples\n",
    "            # exec conformal prediction\n",
    "            test_predictions1 = compute_cp(test_predictions,cp_settings)\n",
    "            test_predictions2 = compute_weighted_cp(test_predictions,cp_settings)\n",
    "        else:\n",
    "            print('conformal prediction implemented on point predictions')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    # Plot test predictions\n",
    "    plot_quantiles(test_predictions1, target=PF_task_name)\n",
    "    plot_quantiles(test_predictions2, target=PF_task_name)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    # Compute pinball score\n",
    "    if exec_CP:\n",
    "        if exper_setup[:5]=='point':\n",
    "            quantiles_levels = PrTSF_eng.__build_target_quantiles__(cp_settings['target_alpha'])\n",
    "        else:\n",
    "            print('Error')\n",
    "    else:\n",
    "        quantiles_levels = PrTSF_eng.model_configs['target_quantiles']\n",
    "\n",
    "    pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "    pinball_scores = compute_pinball_scores(y_true=test_predictions1[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                            pred_quantiles=test_predictions1.loc[:,test_predictions1.columns != PF_task_name].\n",
    "                                            to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                            quantiles_levels=quantiles_levels)\n",
    "\n",
    "    delta_cov = compute_delta_cov(y_true=test_predictions1[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                            pred_quantiles=test_predictions1.loc[:,test_predictions1.columns != PF_task_name].\n",
    "                                            to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                            quantiles_levels=quantiles_levels)\n",
    "    \n",
    "    delta_cov_weighted = compute_delta_cov(y_true=test_predictions2[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                            pred_quantiles=test_predictions2.loc[:,test_predictions2.columns != PF_task_name].\n",
    "                                            to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                            quantiles_levels=quantiles_levels)\n",
    "\n",
    "    rmse_score = rmse(y_true=test_predictions1[PF_task_name].to_numpy().reshape(-1, pred_steps),\n",
    "                      y_pred=test_predictions1.loc[:, 0.5].to_numpy().reshape(-1, pred_steps))\n",
    "\n",
    "    results_rmse.append(rmse_score)\n",
    "    results_d_cov.append(delta_cov)\n",
    "    results_weighted_d_cov.append(delta_cov_weighted)\n",
    "\n",
    "    if hyper_mode == 'optuna_tuner':\n",
    "        hyper_mode = 'load_tuned'\n",
    "#print(pinball_scores)\n",
    "print(\"delta cov\", results_d_cov)\n",
    "print(\"weighted delta cov\", results_weighted_d_cov)\n",
    "print(\"rmse\", results_rmse)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODER MODEL WITH ALSO ALL THE PAST FORECAST FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_winkler_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the Winkler score on the test results\n",
    "    return: Winkler scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break\n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        delta_n = Upper - Lower\n",
    "        idx_up = np.greater(y_true, Upper)\n",
    "        idx_down = np.greater(Lower, y_true)\n",
    "        winkler = (idx_down * (delta_n + 2 / (1 - q * 2) * (Lower - y_true)) + idx_up * (\n",
    "                delta_n + 2 / (1 - q * 2) * (y_true - Upper)) + (~(idx_up | idx_down)) * delta_n)\n",
    "\n",
    "        loss_q = np.mean(winkler, axis=0)\n",
    "        score.append(loss_q)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "#exper_setup = 'N-TRANSF'\n",
    "exper_setup = 'N-TRANSF'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Load experiments configuration from json file\n",
    "configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "# Load dataset\n",
    "dir_path = os.getcwd()\n",
    "ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Instantiate recalibratione engine\n",
    "PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                               data_configs=configs['data_config'],\n",
    "                               model_configs=configs['model_config'])\n",
    "\n",
    "# Get model hyperparameters (previously saved or by tuning)\n",
    "model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "# Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "test_predictions = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                               plot_history=plot_train_history,\n",
    "                                               plot_weights=plot_weights)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Compute pinball score\n",
    "quantiles_levels = PrTSF_eng.model_configs['target_quantiles']\n",
    "pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "pinball_scores = compute_pinball_scores(y_true=test_predictions[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions.loc[:,test_predictions.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Plot test predictions\n",
    "plot_quantiles(test_predictions, target=PF_task_name)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    #print(quantiles_levels)\n",
    "    score = []\n",
    "    EC = []\n",
    "   \n",
    "    #quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels)-1)/2):]\n",
    "    \n",
    "    #print(useful_quantiles)\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        if q >= 0.5:\n",
    "            break       \n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        idx_up = np.greater_equal( Upper, y_true)\n",
    "        idx_down = np.greater_equal( y_true, Lower)\n",
    "      \n",
    "        EC_alpha = np.mean(idx_up & idx_down)#quale asse\n",
    "\n",
    "        print(EC_alpha) \n",
    "        print(1-q*2) \n",
    "\n",
    "        #score.append(delta_cov)\n",
    "        EC.append(np.abs(EC_alpha-(1-q*2)))#check\n",
    "        #print(1-q*2)\n",
    "\n",
    "    \n",
    "    score = 1/(2*(useful_quantiles[-1]-useful_quantiles[0]))*np.sum(EC)\n",
    "    print(EC)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "delta_cov = compute_delta_cov(y_true=test_predictions[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                        pred_quantiles=test_predictions.loc[:,test_predictions.columns != PF_task_name].\n",
    "                                        to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                        quantiles_levels=quantiles_levels)\n",
    "print(delta_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the hours from 00:00 to 23:00\n",
    "average_pinball=np.mean(pinball_scores, axis=1)\n",
    "hours = np.arange(24)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(hours, pinball_scores)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('PInball Score')\n",
    "plt.title('Pinball Score vs Hour of the Day')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPLEMENTED FUNCTIONS\n",
    "from cProfile import label\n",
    "from pickle import TRUE\n",
    "from matplotlib.pyplot import plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Flag è stringa per dire che metrica usare\n",
    "#average è un boleano, dice se calcolare hourly o mean, di default calcola hourly\n",
    "def compute_metrics(predicted, true, flag, average=False):\n",
    "    if average:    \n",
    "        if flag == 'RMSE':\n",
    "            error=  np.sqrt(np.mean(np.square(true - predicted)))    \n",
    "        elif flag == 'MAE':\n",
    "            error=np.mean((np.abs(true-predicted)))\n",
    "        elif flag == 'sMAPE':\n",
    "            error= 100*2*np.mean(np.abs(np.abs(true-predicted))/(np.abs(true)+np.abs(predicted)))\n",
    "        else:\n",
    "            print(\"Not a valid metric\")\n",
    "            return 0\n",
    "    else:\n",
    "        error=np.zeros(24)   \n",
    "        idx2=predicted.index            \n",
    "        if flag == 'RMSE':\n",
    "            for i in np.arange(24):\n",
    "                indices= idx2.hour==idx2[i].hour\n",
    "                error[i]=  np.sqrt(np.mean(np.square(true[indices] - predicted[indices])))    \n",
    "        elif flag == 'MAE':\n",
    "            for i in np.arange(24):\n",
    "                indices= idx2.hour==idx2[i].hour\n",
    "                error[i]= np.mean((np.abs(true[indices]-predicted[indices])))\n",
    "        elif flag == 'sMAPE':\n",
    "            for i in np.arange(24):\n",
    "                indices= idx2.hour==idx2[i].hour\n",
    "                error[i]= 100*2*np.mean(np.abs(true[indices]-predicted[indices])/(np.abs(true[indices])+np.abs(predicted[indices])))\n",
    "        else:\n",
    "            print(\"Not a valid metric\")\n",
    "            return error \n",
    "    return error\n",
    "  \n",
    "\n",
    "def full_evaluation(predicted, true):\n",
    "    metrics={\"RMSE\", \"MAE\", \"sMAPE\" }\n",
    "    hours = [f\"{hour:02}:00\" for hour in range(24)]\n",
    "    # Add an extra 'Average' row\n",
    "    hours.append('Average')\n",
    "    # Initialize the DataFrame with zeros\n",
    "    full_evaluation=pd.DataFrame(0, index=hours, columns=['RMSE', 'MAE', 'sMAPE'])\n",
    "    for st in metrics:\n",
    "        full_evaluation.loc[hours[:-1],st]=compute_metrics(true, predicted, st)\n",
    "        full_evaluation.loc[hours[-1],st]=compute_metrics(true, predicted, st, TRUE)\n",
    "        print(full_evaluation.loc[hours[-1],st], st)\n",
    "\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    idx=hours[:-1]\n",
    "    ones_vec=np.ones(24)\n",
    "    for st in metrics:\n",
    "        ax1.plot(idx,full_evaluation.loc[idx,st], linestyle=\"-\", linewidth=0.9, label=st)\n",
    "        ax1.plot(idx, ones_vec*full_evaluation.loc['Average',st], linestyle=\"-\", linewidth=0.9, label=st+\"_average\")\n",
    "    tics=hours[0:24:3]\n",
    "    ax1.set_xticks(tics)\n",
    "    #fig1.xticks(ticks=tics)\n",
    "    #fig1.gca().xaxis.set_ticks([tick for tick in ax1.gca().xaxis.get_ticks() if tick in tics])\n",
    "\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Error Metrics\")\n",
    "    fig1.show()\n",
    "    return full_evaluation\n",
    "full_metrics=full_evaluation(test_predictions[0.5], test_predictions[PF_task_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECTRANSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run the recalibration experiments\n",
    "\"\"\"\n",
    "# Author: Alessandro Brusaferri\n",
    "# License: Apache-2.0 license\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tools.PrTSF_Recalib_tools import PrTsfRecalibEngine, load_data_model_configs\n",
    "from tools.prediction_quantiles_tools import plot_quantiles\n",
    "from tools.conformal_prediction import compute_cp\n",
    "from tools.conformal_prediction import compute_weighted_cp\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def compute_pinball_scores(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the pinball score on the test results\n",
    "    return: pinball scores computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for i, q in enumerate(quantiles_levels):\n",
    "        error = np.subtract(y_true, pred_quantiles[:, :, i])\n",
    "        loss_q = np.maximum(q * error, (q - 1) * error)\n",
    "        score.append(np.expand_dims(loss_q,-1))\n",
    "    score = np.mean(np.concatenate(score, axis=-1), axis=0)\n",
    "    return score\n",
    "\n",
    "def compute_delta_cov(y_true, pred_quantiles, quantiles_levels):\n",
    "    \"\"\"\n",
    "    Utility function to compute the delta coverage on the test results\n",
    "    return: delta coverage computed for each quantile level and each step in the pred horizon\n",
    "    \"\"\"\n",
    "\n",
    "    EC = []\n",
    "\n",
    "    # quantile levels must have symmetric quantiles and also the 0.5 quantile\n",
    "    useful_quantiles = quantiles_levels[-int((np.size(quantiles_levels) - 1) / 2):]\n",
    "    useful_quantiles.reverse()\n",
    "\n",
    "    for i, q in enumerate(useful_quantiles):\n",
    "        Upper = (pred_quantiles[:, :, -i - 1])\n",
    "        Lower = (pred_quantiles[:, :, i])\n",
    "\n",
    "        print(q)\n",
    "\n",
    "        idx_up = np.greater_equal(Upper, y_true)\n",
    "        idx_down = np.greater_equal(y_true, Lower)\n",
    "        EC_alpha = np.mean(idx_up & idx_down)  # quale asse\n",
    "\n",
    "        # score.append(delta_cov)\n",
    "        EC.append(np.abs(EC_alpha - (1-(1-q)*2) ))  # check\n",
    "    score = 1 / (2 * (useful_quantiles[0] - useful_quantiles[-1])) * np.sum(EC)\n",
    "    return score\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = np.square(y_true - y_pred).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = np.square(y_true - y_pred).mean()\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Set PEPF task to execute\n",
    "PF_task_name = 'EM_price'\n",
    "# Set Model setup to execute\n",
    "exper_setup = 'point-DECTRANSF'\n",
    "results_d_cov = []\n",
    "results_weighted_d_cov = []\n",
    "results_rmse = []\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Set run configs\n",
    "run_id = 'recalib_opt_grid_1_1'\n",
    "# Load hyperparams from file (select: load_tuned or optuna_tuner)\n",
    "hyper_mode = 'load_tuned'\n",
    "# Plot train history flag\n",
    "plot_train_history=False\n",
    "plot_weights=False\n",
    "\n",
    "\n",
    "num_run = 2\n",
    "for i in range(num_run):\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    # Load experiments configuration from json file\n",
    "    configs=load_data_model_configs(task_name=PF_task_name, exper_setup=exper_setup, run_id=run_id)\n",
    "\n",
    "    # Load dataset\n",
    "    dir_path = os.getcwd()\n",
    "    ds = pd.read_csv(os.path.join(dir_path, 'data', 'datasets', configs['data_config'].dataset_name))\n",
    "    ds.set_index(ds.columns[0], inplace=True)\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    # Instantiate recalibratione engine\n",
    "    PrTSF_eng = PrTsfRecalibEngine(dataset=ds,\n",
    "                                   data_configs=configs['data_config'],\n",
    "                                   model_configs=configs['model_config'])\n",
    "\n",
    "\n",
    "    # Get model hyperparameters (previously saved or by tuning)\n",
    "    model_hyperparams = PrTSF_eng.get_model_hyperparams(method=hyper_mode, optuna_m=configs['model_config']['optuna_m'])\n",
    "\n",
    "    # Exec recalib loop over the test_set samples, using the tuned hyperparams\n",
    "    test_predictions = PrTSF_eng.run_recalibration(model_hyperparams=model_hyperparams,\n",
    "                                                   plot_history=plot_train_history,\n",
    "                                                   plot_weights=plot_weights)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    # Conformal prediction settings\n",
    "    exec_CP = True\n",
    "    # set the size of the calibration set sufficiently large to cover the target alpha (tails)\n",
    "    cp_settings={'target_alpha':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]}\n",
    "    num_cali_samples = 365\n",
    "    #cp_settings={'target_alpha':[0.10]}\n",
    "    #num_cali_samples = 1\n",
    "\n",
    "    if exec_CP:\n",
    "        if exper_setup[:5]=='point':\n",
    "            # build the settings to build PF from point using CP\n",
    "            cp_settings['pred_horiz']=configs['data_config'].pred_horiz\n",
    "            cp_settings['task_name']=configs['data_config'].task_name\n",
    "            cp_settings['num_cali_samples']=num_cali_samples\n",
    "            # exec conformal prediction\n",
    "            test_predictions1 = compute_cp(test_predictions,cp_settings)\n",
    "            test_predictions2 = compute_weighted_cp(test_predictions,cp_settings)\n",
    "        else:\n",
    "            print('conformal prediction implemented on point predictions')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    # Plot test predictions\n",
    "    plot_quantiles(test_predictions1, target=PF_task_name)\n",
    "    plot_quantiles(test_predictions2, target=PF_task_name)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------\n",
    "    # Compute pinball score\n",
    "    if exec_CP:\n",
    "        if exper_setup[:5]=='point':\n",
    "            quantiles_levels = PrTSF_eng.__build_target_quantiles__(cp_settings['target_alpha'])\n",
    "        else:\n",
    "            print('Error')\n",
    "    else:\n",
    "        quantiles_levels = PrTSF_eng.model_configs['target_quantiles']\n",
    "\n",
    "    pred_steps = configs['model_config']['pred_horiz']\n",
    "\n",
    "    pinball_scores = compute_pinball_scores(y_true=test_predictions1[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                            pred_quantiles=test_predictions1.loc[:,test_predictions1.columns != PF_task_name].\n",
    "                                            to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                            quantiles_levels=quantiles_levels)\n",
    "\n",
    "    delta_cov = compute_delta_cov(y_true=test_predictions1[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                            pred_quantiles=test_predictions1.loc[:,test_predictions1.columns != PF_task_name].\n",
    "                                            to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                            quantiles_levels=quantiles_levels)\n",
    "    \n",
    "    delta_cov_weighted = compute_delta_cov(y_true=test_predictions2[PF_task_name].to_numpy().reshape(-1,pred_steps),\n",
    "                                            pred_quantiles=test_predictions2.loc[:,test_predictions2.columns != PF_task_name].\n",
    "                                            to_numpy().reshape(-1, pred_steps, len(quantiles_levels)),\n",
    "                                            quantiles_levels=quantiles_levels)\n",
    "\n",
    "    rmse_score = rmse(y_true=test_predictions1[PF_task_name].to_numpy().reshape(-1, pred_steps),\n",
    "                      y_pred=test_predictions1.loc[:, 0.5].to_numpy().reshape(-1, pred_steps))\n",
    "\n",
    "    results_rmse.append(rmse_score)\n",
    "    results_d_cov.append(delta_cov)\n",
    "    results_weighted_d_cov.append(delta_cov_weighted)\n",
    "\n",
    "    if hyper_mode == 'optuna_tuner':\n",
    "        hyper_mode = 'load_tuned'\n",
    "#print(pinball_scores)\n",
    "print(\"delta cov\", results_d_cov)\n",
    "print(\"weighted delta cov\", results_weighted_d_cov)\n",
    "print(\"rmse\", results_rmse)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print('Done!')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
